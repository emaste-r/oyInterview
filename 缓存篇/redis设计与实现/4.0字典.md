# 字典
字典的主要用途：
```
1、数据库键空间，key space；
2、Hash类型键的底层实现之一。
```
链接：
```
https://redisbook.readthedocs.io/en/latest/internal-datastruct/dict.html
```


## key space
什么是key space
```
redis是一个键值对数据库，每一个数据库对应一个字典，这个字典就是key space。
```
set
```
设置一个字符串键到key space
```

get
```
从key space获取一个字符串键的value
```

flushdb
```
清空这个字典
```

dbsize
```
返回字典的大小
```

randomkey
```
随机返回一个key，多用于惰性删除吧这里...
```

## 用作 Hash 类型键的底层实现之一

hash键的底层实现：
```
1、字典
2、压缩列表
```


# 4.1 字典的实现

## dictEntry: 
```dtd
typedef struct dictEntry{
    void *key;
    union{
        void *val;
        uint64_t u64;
        int64_t s64;
    } v;
    
    // 指向下个哈希表节点，形成链表
    struct dictEntry *next;
} dictEntry;
```
## dictht:
```dtd
typedef struct dictht{
    // 哈希表数组
    dictEntry **table;
    
    // 哈希表大小
    unsigned long size;
    
    // 哈希表大小掩码，用于计算掩码值， = size -1 
    unsigned long sizemask;
    
    // 哈希表已有节点的数量
    unsigned long used;
}dictht;
```

空的哈希表：
![redis 字典结构图.jpg](../../imgs/redis/redis字典结构图.jpg?raw=true)

有 2 个结点的哈希表：
![redis字典结构图3.jpg](../../imgs/redis/redis字典结构图3.jpg?raw=true)


## dict
```dtd
typedef struct dict{
    // 特定类型函数
    dictType *type;
    
    // 私有数据
    void *privData;

    // 2 个哈希表
    dictht ht[2] ;
    
    // rehash不进行时，-1
    int rehashidx;

}dict;
```
简单的字典结构如下
![redis字典结构2.png](../../imgs/redis/redis字典结构2.png?raw=true)

其中的 dictType 和 privdata竟然是为了多态，C 语言的多态这么简单粗暴的吗？
```dtd
typedef struct dictType{
    // 计算 hash 值的函数
    unsigned int (*hashFunction)(const void *key);
    
    // 复制 key 的函数
    void *(*keyDup)(void *privdata, const void *key);

    // 复制 value 的函数
    void *(*valDup)(void *privdata, const void *obj);

    // 对比 key 的函数
    int (*keyCompare)(void *privdata, const void *key1, const void *key2);

    // 销毁 key 的函数
    void (*keyDestructor)(void *privdata, const void *key);

    // 销毁 value 的函数
    void (*valDestructor)(void *privdata, const void *obj);
} dictType;
```

简单的字典结构如下
![无rehash时的字典结构图.png](../../imgs/redis/无rehash时的字典结构图.png?raw=true)


# 4.2 哈希算法
一个新的键值对放入字典的步骤如下：
* 根据键值对的key通过哈希算法计算出哈希值
* 根据哈希值计算出索引值
* 创建一个新的dictEntry，包含了key和value
* 将这个新的dictEntry放到哈希表指定的索引位置上


哈希值、索引值计算代码：
```
// 字典的type可以设置不同的哈希函数，这就是多态吗？
hash = dict -> type -> hashFunction(key);

// 根据rehash的进度，ht[x]可以是hx[0]，也可以是hx[1]
index = hash & dict -> ht[x].sizemask;
```

你不好奇redis现在采用的hash算法是什么吗？
```
2008年的 MurmurHash2
```
它的优点：
```
对于规律性较强的key，MurmurHash的随机分布特征表现更良好
```


## 4.3 解决键冲突

再怎么优秀的哈希算法，总会出现键冲突的情况。
字典dictEntry的next字段可以让相同哈希值的组成链表。这就是：
```
链地址法解决键冲突。
```
特别的：
```
为了插入速度考虑：采用的是头插法。
```

## 4.4 rehash
这个就要说一下负载因子了： `load factor`， 计算公式：
```
load_factor = dict.ht[0].used / dict.ht[0].size
```
作用，判断何时该扩展，何时该收缩：
```
随着字典的操作不断进行，哈希表保存的数据可以增大或者减少，这个时候为了让负载因子在一个合理范围内，就需要rehash。
```
rehash的步骤：
* 给ht[1] 分配空间
    * 如果是扩展操作：空间大小  = 比 ht[0].used * 2 大或等于的第一个 2^n。
    * 如果是收缩操作：空间大小  = 比 ht[0].used 大或等于的第一个 2^n。
* rehash指的是重新计算hash值和索引值，把键值对设置到ht[1]对应的新的索引位置
* 当ht[0]的dictEntry都迁移到ht[1]的时候，把ht[0]释放，把ht[1]指定为ht[0]，为ht[1]重新生成一个哈希表

以下是rehash过程中，ht[0]数据都迁移到ht[1]的图：
![rehash过程图.png](../../imgs/redis/rehash过程图.png?raw=true)


扩展和收缩的判断标准：
* 扩展
    * 服务器目前没有执行bgsave或者bgwriteof命令，load_factor >= 1
    * 服务器目前正在执行bgsave或者bgwriteof命令，load_factor >= 5
* 收缩
    * load_factor <= 0.1
    
为何扩展时有双标呢？
```
1、bgsave和bgwriteof命令会创建一个子进程；
2、操作系统对于子进程会采用写时复制技术来优化子进程的利用效率；
3、所以在子进程存在期间，尽可能避免哈希表扩展操作，以避免不必要的内存写入，最大化节约内存。
```
写时复制技术：
```
1、fork()之后，kernel把父进程中所有的内存页的权限置为read_only，子进程的空间地址指向父进程。
2、当父子进程都只读内存时，相安无事。
3、当其中某一个进程有写操作（exec()，cpu硬件检测到n内存页是read_only，直接触发页异常中断(page-fault)，陷入kernel的一个中断例程；
4、中断例程中，kernel会把异常的页复制一份，于是父子进程各持有一份独立的页。
```
COW：[掘进关于Copy on write的介绍](https://juejin.im/post/6844903702373859335)

解释为啥要避免子进程时写操作：
```
1、bgsave或者bgwriteof的时候，会fork()子进程去读数据，并写入磁盘；
2、总体来看，redis读操作是远远高于写操作的，如果这个时候扩展哈希表，会触发大量的的写操作，导致很多kernel级别的page-fault错误，会耗费不少性能在复制内存页上。
3、所以才要把负载因子提高，尽最大可能避免这个COW(copy on write).
```


## 4.5 渐进式rehash
背景：
```
如果哈希表里面不只有几十、几百个dictEntry，而是几千万的，不可能一次性rehash完毕，所以需要慢慢来。
```

步骤：
* 1、和rehash一样，先计算ht[1]的size
    * 扩展： ht[0] * 2 比这个数大或等于的第一个2^n
    * 收缩： ht[0] 比这个数大或等于的第一个2^n
* 2、在dict中维持一个rehashidx，使其等于0（默认-1），表示rehash开始
* 3、rehash期间，系统每次对字典的增删改查，都会**顺便**拿rehashidx对应的dictEntry挪到ht[1]上。   
* 4、rehashidx ++
* 5、重复3，4两个动作知道ht[0]数据都迁移完毕，rehashidx设置为-1，表示rehash结束。
    
rehash期间怎么查数据？
```
要同时在ht[0]和ht[1]上面查找，先ht[0]再ht[1]；
```
rehash期间怎么删除数据？
```
要同时在ht[0]和ht[1]上面查找，先ht[0]再ht[1]，找到后删除；
```
rehash期间怎么删除更新？
```
要同时在ht[0]和ht[1]上面查找，先ht[0]再ht[1]，找到后更新；
```
rehash期间怎么新增数据？
```
只能往ht[1]上面新增数据
```

## 4.6 字典API
```
无非是增删改查，全是O(1)
获取随机key O(1)
+ 
创建字典 O(1)
+ 
释放字典 O(n)

```
